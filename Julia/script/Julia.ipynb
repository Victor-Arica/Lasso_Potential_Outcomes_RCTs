{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea71b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Pkg\n",
    "#Pkg.add(\"XLSX\")\n",
    "#Pkg.add(\"Distributions\")\n",
    "#Pkg.add(\"Lasso\")\n",
    "#Pkg.add(\"GLMNet\")\n",
    "#Pkg.add(\"MLJ\")\n",
    "#Pkg.add(\"MLBase\")\n",
    "#Pkg.add(\"HDMjl\")\n",
    "#import Pkg; Pkg.add(\"MLJScikitLearnInterface\")\n",
    "#Pkg.add(\"HypothesisTests\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b5af578",
   "metadata": {},
   "outputs": [],
   "source": [
    "using XLSX\n",
    "using Distributions\n",
    "using DataFrames\n",
    "using Dates\n",
    "using Plots\n",
    "using Random\n",
    "using LinearAlgebra\n",
    "using LaTeXStrings\n",
    "using Lasso\n",
    "using MLBase\n",
    "using Statistics\n",
    "using GLMNet\n",
    "using MLJ\n",
    "using HDMjl\n",
    "using GLM\n",
    "using CSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369a51c4",
   "metadata": {},
   "source": [
    "2 Lasso (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac323a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(XLSX.readtable(\"Districtwise_literacy_rates.xlsx\", \"2015_16_Districtwise\"))\n",
    "dropmissing!(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1348acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph1=histogram(\n",
    "    [df.MALE_LIT, df.FEMALE_LIT],       \n",
    "    bins = 0:10:150,\n",
    "    xlabel = \"Literacy rate\",\n",
    "    ylabel = \"Frequency\",\n",
    "    title = \"Female and Male literacy rate\",\n",
    "    label = [\"Male\" \"Female\"],         \n",
    "    ylim = (0, 625),\n",
    "    alpha = 0.6\n",
    ") \n",
    "\n",
    "\n",
    "savefig(Graph1, \"Histogram.pdf\")                        \n",
    "#Como se ve en el gráfico, en India la distribución de la tasa de alfabetismo en hombres está sesgada a la izquierda, mientras que la de las mujeres parece que tiene una distribución normal. \n",
    "#Es decir, en el caso de los hombres hay más observaciones en el lado derecho de la distribución o es más probable que tengan tasas de alfabetismo de más de 70% y unos pocos casos en los que el alfabetismo llega al rededor de 50% y 60%.\n",
    "#En el caso de las mujeres, parece que la probabilidad de tener una alta tasa de alfabetización es similar a la de tener una baja.\n",
    "#Asimismo, hay una mayor cantidad de hombres que saben leer y escribir a comparacion de las mujeres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8b6aed",
   "metadata": {},
   "source": [
    "Low-dimensional specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea83d805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48596087340293526"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.seed!(12)\n",
    "y = df[:, \"FEMALE_LIT\"]\n",
    "Z = select(df, Not([:FEMALE_LIT]))\n",
    "column_names = names(Z)\n",
    "y=Float64.(y)\n",
    "df.GROWTHRATE = Float64.(df.GROWTHRATE)\n",
    "df.SCH2 = Int.(df.SCH2)\n",
    "df.SELE2 = Int.(df.SELE2)\n",
    "df.CLS2 = Int.(df.CLS2)\n",
    "df.TCH2 = Int.(df.TCH2)\n",
    "df.SCOMP2 = Int.(df.SCOMP2)\n",
    "df.SEXRATIO = Int.(df.SEXRATIO)\n",
    "df.P_URB_POP = Float64.(df.P_URB_POP)\n",
    "df.TOTPOPULAT = Float64.(df.TOTPOPULAT)\n",
    "\n",
    "\n",
    "\n",
    "df.GROWTHRATE2=df.GROWTHRATE.^ 2\n",
    "df.P_URB_POP2=df.P_URB_POP.^ 2\n",
    "df.SEXRATIO2=df.SEXRATIO.^ 2\n",
    "df.TOTPOPULAT2=df.TOTPOPULAT.^ 2\n",
    "df.SCH2_cuadrado=df.SCH2.^ 2\n",
    "df.SELE2_cuadrado=df.SELE2.^ 2\n",
    "df.SCOMP2_cuadrado=df.SCOMP2.^ 2\n",
    "df.CLS2_cuadrado=df.CLS2.^ 2\n",
    "df.TCH2_cuadrado=df.TCH2.^ 2\n",
    "\n",
    "basic_formula = @formula(FEMALE_LIT ~ 1 +STATNAME+GROWTHRATE+P_URB_POP+ SEXRATIO+TOTPOPULAT+SCH2+SELE2+SCOMP2+CLS2+TCH2)  \n",
    "Z_base = modelmatrix(basic_formula, df);\n",
    "\n",
    "train_sample = rand(Float64, size(df)[1]) .< 0.75\n",
    "test_sample = .!(train_sample)\n",
    "y_train, y_test = y[train_sample], y[test_sample]\n",
    "X_train, X_test = Z_base[train_sample, :], Z_base[test_sample, :];\n",
    "y_train=Float64.(y_train)\n",
    "y_test=Float64.(y_test)\n",
    "\n",
    "lr_base = lm(X_train, y_train);\n",
    "\n",
    "basic_mse_testing = mean((GLM.predict(lr_base, X_test) - y_test) .^ 2)\n",
    "\n",
    "basic_r2_testing = 1 - basic_mse_testing / var(y_test)\n",
    "#Según el R cuadrado, parece que el modelo explica bien la variabilidad en la tasa de alfabetismo de las mujeres en India"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef027f6",
   "metadata": {},
   "source": [
    "High-dimensional (flexible) specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "815388b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.316659865854264"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "flex_formula = @formula(FEMALE_LIT ~ 1 +STATNAME+ GROWTHRATE + P_URB_POP + SEXRATIO + TOTPOPULAT + SCH2 + SELE2 + SCOMP2 + CLS2 + TCH2+GROWTHRATE2 + P_URB_POP2 + SEXRATIO2 + TOTPOPULAT2 + SCH2_cuadrado + SELE2_cuadrado + SCOMP2_cuadrado + CLS2_cuadrado + TCH2_cuadrado+(GROWTHRATE+GROWTHRATE2)*( P_URB_POP + SEXRATIO + TOTPOPULAT + SCH2 + SELE2 + SCOMP2 + CLS2 + TCH2))\n",
    "Z_flex = modelmatrix(flex_formula, df);\n",
    "\n",
    "X_train, X_test = Z_flex[train_sample, :], Z_flex[test_sample, :];\n",
    "\n",
    "lr_flex = lm(X_train, y_train);\n",
    "\n",
    "flexible_mse_testing = mean((GLM.predict(lr_flex, X_test) - y_test) .^ 2)\n",
    "flexible_r2_testing = 1 - flexible_mse_testing / var(y_test)\n",
    "\n",
    "flexible_r2_testing\n",
    "#El R-cuadrado de estimar con OLS los terminos cuadraticos e interacciones es extremadamente negativo. El estimador OLS no es muy útil para estos casos con una gran cantidad de regresores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb68edd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5576930233426556"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdm_lasso = rlasso(Z_flex, y, intercept = false)\n",
    "\n",
    "hdm_predictions = Z_flex * hdm_lasso[\"coefficients\"];\n",
    "R2_Lasso=1 - mean((hdm_predictions - y) .^ 2) / var(y)\n",
    "R2_table = DataFrame(\n",
    "    Modelo = [\"Basic_OLS\", \"Flexible_OLS\", \"Lasso\"],\n",
    "    R² = [basic_r2_testing, flexible_r2_testing, R2_Lasso]\n",
    ")\n",
    "CSV.write(\"R2_table.csv\", R2_table)\n",
    "R2_Lasso\n",
    "#Al estimar con Lasso el R cuadrado es incluso más alto que haciendo OLS al modelo base. Esto muestra que para casos de alta dimensionalidad Lasso es más util que hacer un OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2d9687",
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoRegressor = @load LassoRegressor pkg=MLJScikitLearnInterface\n",
    "lambdas = [10000, 5000, 1000, 500, 100, 50, 10, 5, 1, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001]\n",
    "num_coefs_nonzero = Int[]\n",
    "\n",
    "for lambda in lambdas\n",
    "    lasso_model = LassoRegressor(alpha=lambda, fit_intercept=false)\n",
    "    lasso_machine = machine(lasso_model, X_train, y_train)\n",
    "    fit!(lasso_machine, verbosity=0) \n",
    "    coefficients = fitted_params(lasso_machine).coef\n",
    "    n_nonzero = sum(abs.(coefficients) .> 1e-10)\n",
    "    push!(num_coefs_nonzero, n_nonzero)\n",
    "  \n",
    "end\n",
    "\n",
    "results_df = DataFrame(\n",
    "    lambda = lambdas,\n",
    "    n_nonzero_coefs = num_coefs_nonzero,\n",
    ")\n",
    "\n",
    "p1= plot(lambdas, num_coefs_nonzero, \n",
    "          marker=:circle, linewidth=2,\n",
    "          xlabel=\"λ\", ylabel=\"Nonzero coefficients\",\n",
    "          title=\"Coefficients vs Lambda\", legend=false)\n",
    "\n",
    "CSV.write(\"Number of Nonzero coefficients.csv\", results_df)         \n",
    "savefig(p1, \"Nonzero coefficients vs Lambda.pdf\") \n",
    "#En el gráfico se ve que cuanto mayor sea el Lambda hay una menor cantidad de coeficientes diferente a cero. Es decir, se castiga mucho más y el modelo es más parsimonioso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bc688d",
   "metadata": {},
   "source": [
    "3. Potential Outcomes and RCTs (9 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd022fb",
   "metadata": {},
   "source": [
    "3.1 Data Simulation (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02bcf436",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "using DataFrames\n",
    "using Statistics\n",
    "using Distributions\n",
    "using HypothesisTests: EqualVarianceTTest, pvalue\n",
    "using GLM\n",
    "using GLMNet\n",
    "using CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9260e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(12345678)\n",
    "n=1000\n",
    "e=rand(Normal(0,1),n)\n",
    "x1 = rand(Normal(0,1), n)\n",
    "x2 = rand(Normal(5,2), n)\n",
    "x3 = rand(Uniform(0,10), n)\n",
    "x4 = rand(n)\n",
    "D = Int.(rand(Bernoulli(0.5), n))\n",
    "Y = 2 .* D .+ 0.5 .* x1 .- 0.3 .* x2 .+ 0.2 .* x3 .+ e\n",
    "\n",
    "df = DataFrame(\n",
    "    Y = Y,\n",
    "    D = D,\n",
    "    x1 = x1,\n",
    "    x2 = x2,\n",
    "    x3 = x3,\n",
    "    x4 = x4,\n",
    "    e = e\n",
    ")\n",
    "CSV.write(\"Data_simulation.csv\", df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3805ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = [:x1, :x2, :x3, :x4]\n",
    "\n",
    "balance_table = DataFrame(\n",
    "    Variable = String[],\n",
    "    Mean_Control = Float64[],\n",
    "    Mean_Treated = Float64[],\n",
    "    Difference = Float64[],\n",
    "    P_value = Float64[]\n",
    ")\n",
    "\n",
    "for x in covariates\n",
    "    treated = df[df.D .== 1, x]\n",
    "    control = df[df.D .== 0, x]\n",
    "\n",
    "    test = EqualVarianceTTest(treated, control)\n",
    "\n",
    "    mean_treated = mean(treated)\n",
    "    mean_control = mean(control)\n",
    "    diff = mean_treated - mean_control\n",
    "    p_val = pvalue(test)\n",
    "\n",
    "    push!(balance_table, (string(x), mean_control, mean_treated, diff, p_val))\n",
    "end\n",
    "\n",
    "display(balance_table)\n",
    "#en la tabla de balance se ve que las diferencias son muy pequeñas y no significativas. Esto indica que al haberse asignado el tratamiento de forma aleatoria, las caracteristicas de las observaciones de ambos grupos son en promedio similares.\n",
    "CSV.write(\"balance_table.csv\", balance_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eb7bb5",
   "metadata": {},
   "source": [
    "3.2 Estimating the Average Treatment Effect (3 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef5892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = lm(@formula(Y ~ D), df)\n",
    "model_2 = lm(@formula(Y ~ D+x1+x2+x3+x4), df)\n",
    "#el coeficiente de la variable de tratamiento se mantiene con valores similares y significativos, pero controlando por las otras variables el coeficiente estimado se aleja un poco más del parámetro. El error estandar disminuye cuando se incluyen las otras variables.\n",
    "CSV.write(\"model_1.csv\", DataFrame(StatsBase.coeftable(model_1)))\n",
    "CSV.write(\"model_2.csv\", DataFrame(StatsBase.coeftable(model_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c275d01",
   "metadata": {},
   "source": [
    "3.3 LASSO and Variable Selection (3 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86543502",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Y                    \n",
    "X = Matrix(select(df, [:x1, :x2, :x3, :x4]))  \n",
    "fit = glmnetcv(X, y, alpha=1,intercept=true)\n",
    "betas_l1 = fit.path.betas[:,argmin(fit.meanloss)];\n",
    "Betas_df = DataFrame([(Symbol(\"Beta$(i)\") => [betas_l1[i]]) for i in 1:length(betas_l1)]...)\n",
    "CSV.write(\"Betas_lasso.csv\", Betas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d092b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso = lm(@formula(Y ~ D+x1+x2+x3), df)\n",
    "#Se escogen los 3 primero regresores y el coeficiente estimado se acerca más que en el caso con 4 controles, pero la diferencia no es tanta.\n",
    "#Al ser un proceso generador de datos con tan pocas variables Lasso solo elimina una variable y es justo la que no esta en el PGD original. \n",
    "#La ventaja de Lasso podria ser que dismiuye el error estandar en este caso, lo que permite estimar con algo más de precision el parametro.\n",
    "CSV.write(\"model_lasso.csv\", DataFrame(StatsBase.coeftable(model_lasso)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
